{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    graph_state: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_1(state):\n",
    "    print(\"----Node 1----\")\n",
    "    return {\"graph_state\": state['graph_state'] +\"I am \"}\n",
    "\n",
    "def node_2(state):\n",
    "    print(\"----Node 2----\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" happy!\"}\n",
    "\n",
    "def node_3(state):\n",
    "    print(\"----Node 3----\")\n",
    "    return {\"graph_state\": state['graph_state'] +\" sad!\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "def decide_mood(state) -> Literal[\"node_2\", \"node_3\"]:\n",
    "    user_input = state['graph_state']\n",
    "\n",
    "    if random.random() < 0.5:\n",
    "        return \"node_2\"\n",
    "    return \"node_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"node_1\", node_1)\n",
    "builder.add_node(\"node_2\", node_2)\n",
    "builder.add_node(\"node_3\", node_3)\n",
    "\n",
    "# Logic\n",
    "builder.add_edge(START, \"node_1\")\n",
    "builder.add_conditional_edges(\"node_1\", decide_mood)\n",
    "builder.add_edge(\"node_2\", END)\n",
    "builder.add_edge(\"node_3\", END)\n",
    "\n",
    "# add\n",
    "graph = builder.compile()\n",
    "\n",
    "# view graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Node 1----\n",
      "----Node 2----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'graph_state': 'Hi, I am Siddharth.I am  happy!'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({'graph_state': 'Hi, I am Siddharth.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes that is right\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great would you like to learn about\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage,HumanMessage, SystemMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.extend([HumanMessage(content=f\"Yes that is right\", name=\"Lance\")])\n",
    "messages.extend([AIMessage(content=f\"Great would you like to learn about\", name=\"Model\")])\n",
    "messages.extend([HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\")])\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Invoke the model with messages\n",
    "result = llm.invoke([\"Hello!\"])\n",
    "print(type(result))\n",
    "# print(result.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<>:6: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "C:\\Users\\PARTHIV\\AppData\\Local\\Temp\\ipykernel_13572\\1464925785.py:6: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "  return 3(a * b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is 12 multiplied by 5?\n",
      "Thought: The operation needs to be performed on two numbers.\n",
      "Action: multiply\n",
      "Action Input: (12, 5)\u001b[0mTOOL EXECUTED\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 12 x 5 is 60\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is the result of multiplying 12 and 5 again?\n",
      "Thought: The operation needs to be verified by the system in the original problem statement.\n",
      "Action: multiply\n",
      "Action Input: (12, 5)\u001b[0mTOOL EXECUTED\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 12 x 5 is 60\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is 12 multiplied by 5?\n",
      "Thought: I can use my multiplication tool to solve this problem.\n",
      "Action: multiply\n",
      "Action Input: (12, 5)\u001b[0mTOOL EXECUTED\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 12 x 5 is 60\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is the input for the multiply function?\n",
      "Thought: The input should be in the format '(a, b)' or 'a b', where a and b are integers.\n",
      "Action: parse\n",
      "Action Input: (12, 5)\u001b[0m\n",
      "Observation: parse is not a valid tool, try one of [multiply].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is 12 multiplied by 5?\n",
      "Thought: I need to perform multiplication on two numbers.\n",
      "Action: multiply\n",
      "Action Input: (12, 5)\u001b[0mTOOL EXECUTED\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 12 x 5 is 60\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is 12 multiplied by 5?\n",
      "Thought: I have access to a tool that can perform multiplication on two integers.\n",
      "Action: parse\n",
      "Action Input: (12, 5)\u001b[0m\n",
      "Observation: parse is not a valid tool, try one of [multiply].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI understand the format you'd like me to follow. Here's my response:\n",
      "\n",
      "Question: What is 12 multiplied by 5?\n",
      "Thought: The input should be in the format '(a, b)' or 'a b', where a and b are integers.\n",
      "Action: parse\n",
      "Action Input: (12, 5)\u001b[0m\n",
      "Observation: parse is not a valid tool, try one of [multiply].\n",
      "Thought:\u001b[32;1m\u001b[1;3mQuestion: What is the result of multiplying 12 and 5 again?\n",
      "Thought: The operation needs to be verified by the system in the original problem statement.\n",
      "Action: multiply\n",
      "Action Input: (12, 5)\u001b[0mTOOL EXECUTED\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe result of 12 x 5 is 60\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is 12 multiplied by 5?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m \u001b[39m# prompt = \"Can u tell me a joke?\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m response \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt})\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAgent Response:\u001b[39m\u001b[39m\"\u001b[39m, response[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1624\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1624\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m   1625\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1626\u001b[0m         color_mapping,\n\u001b[0;32m   1627\u001b[0m         inputs,\n\u001b[0;32m   1628\u001b[0m         intermediate_steps,\n\u001b[0;32m   1629\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m   1630\u001b[0m     )\n\u001b[0;32m   1631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1632\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m   1633\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m   1634\u001b[0m         )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1330\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_take_next_step\u001b[39m(\n\u001b[0;32m   1322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1323\u001b[0m     name_to_tool_map: Dict[\u001b[39mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1327\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1328\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[39mstr\u001b[39m]]]:\n\u001b[0;32m   1329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1330\u001b[0m         [\n\u001b[0;32m   1331\u001b[0m             a\n\u001b[0;32m   1332\u001b[0m             \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_next_step(\n\u001b[0;32m   1333\u001b[0m                 name_to_tool_map,\n\u001b[0;32m   1334\u001b[0m                 color_mapping,\n\u001b[0;32m   1335\u001b[0m                 inputs,\n\u001b[0;32m   1336\u001b[0m                 intermediate_steps,\n\u001b[0;32m   1337\u001b[0m                 run_manager,\n\u001b[0;32m   1338\u001b[0m             )\n\u001b[0;32m   1339\u001b[0m         ]\n\u001b[0;32m   1340\u001b[0m     )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:1358\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1355\u001b[0m     intermediate_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1357\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1358\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_action_agent\u001b[39m.\u001b[39mplan(\n\u001b[0;32m   1359\u001b[0m         intermediate_steps,\n\u001b[0;32m   1360\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1361\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[0;32m   1362\u001b[0m     )\n\u001b[0;32m   1363\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1364\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\agents\\agent.py:804\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[39m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    803\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 804\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m    805\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:318\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    304\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     warned \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     emit_warning()\n\u001b[1;32m--> 181\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \n\u001b[0;32m    359\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39m        `Chain.output_keys`.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    382\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[0;32m    383\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks,\n\u001b[0;32m    384\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m: tags,\n\u001b[0;32m    385\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m: metadata,\n\u001b[0;32m    386\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_name\u001b[39m\u001b[39m\"\u001b[39m: run_name,\n\u001b[0;32m    387\u001b[0m }\n\u001b[1;32m--> 389\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minvoke(\n\u001b[0;32m    390\u001b[0m     inputs,\n\u001b[0;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m config\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m v \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m}),\n\u001b[0;32m    392\u001b[0m     return_only_outputs\u001b[39m=\u001b[39;49mreturn_only_outputs,\n\u001b[0;32m    393\u001b[0m     include_run_info\u001b[39m=\u001b[39;49minclude_run_info,\n\u001b[0;32m    394\u001b[0m )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[39m=\u001b[39m run_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    139\u001b[0m         prompts,\n\u001b[0;32m    140\u001b[0m         stop,\n\u001b[0;32m    141\u001b[0m         callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[0;32m    142\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm\u001b[39m.\u001b[39mbind(stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_kwargs)\u001b[39m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:763\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    756\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    757\u001b[0m     prompts: \u001b[39mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    761\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    762\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(prompt_strings, stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:966\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m get_llm_cache() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    953\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    954\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    964\u001b[0m         )\n\u001b[0;32m    965\u001b[0m     ]\n\u001b[1;32m--> 966\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_helper(\n\u001b[0;32m    967\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39m(new_arg_supported), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    968\u001b[0m     )\n\u001b[0;32m    969\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    970\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_core\\language_models\\llms.py:787\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    778\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    779\u001b[0m     prompts: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 787\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(\n\u001b[0;32m    788\u001b[0m                 prompts,\n\u001b[0;32m    789\u001b[0m                 stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    790\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    791\u001b[0m                 run_manager\u001b[39m=\u001b[39mrun_managers[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m run_managers \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    792\u001b[0m                 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    793\u001b[0m             )\n\u001b[0;32m    794\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    795\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    796\u001b[0m         )\n\u001b[0;32m    797\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    798\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[0m, in \u001b[0;36mOllamaLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m generations \u001b[39m=\u001b[39m []\n\u001b[0;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m--> 288\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream_with_aggregation(\n\u001b[0;32m    289\u001b[0m         prompt,\n\u001b[0;32m    290\u001b[0m         stop\u001b[39m=\u001b[39mstop,\n\u001b[0;32m    291\u001b[0m         run_manager\u001b[39m=\u001b[39mrun_manager,\n\u001b[0;32m    292\u001b[0m         verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    293\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    294\u001b[0m     )\n\u001b[0;32m    295\u001b[0m     generations\u001b[39m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    296\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[0m, in \u001b[0;36mOllamaLLM._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    249\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    254\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m GenerationChunk:\n\u001b[0;32m    255\u001b[0m     final_chunk \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[39mfor\u001b[39;00m stream_resp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    257\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(stream_resp, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    258\u001b[0m             chunk \u001b[39m=\u001b[39m GenerationChunk(\n\u001b[0;32m    259\u001b[0m                 text\u001b[39m=\u001b[39mstream_resp[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m stream_resp \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    260\u001b[0m                 generation_info\u001b[39m=\u001b[39m(\n\u001b[0;32m    261\u001b[0m                     \u001b[39mdict\u001b[39m(stream_resp) \u001b[39mif\u001b[39;00m stream_resp\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdone\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    262\u001b[0m                 ),\n\u001b[0;32m    263\u001b[0m             )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[0m, in \u001b[0;36mOllamaLLM._create_generate_stream\u001b[1;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_create_generate_stream\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     prompt: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    208\u001b[0m     stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    210\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[Mapping[\u001b[39mstr\u001b[39m, Any], \u001b[39mstr\u001b[39m]]:\n\u001b[1;32m--> 211\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    212\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_params(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m     )\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\ollama\\_client.py:170\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    167\u001b[0m   e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m    168\u001b[0m   \u001b[39mraise\u001b[39;00m ResponseError(e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mtext, e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_lines():\n\u001b[0;32m    171\u001b[0m   part \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(line)\n\u001b[0;32m    172\u001b[0m   \u001b[39mif\u001b[39;00m err \u001b[39m:=\u001b[39m part\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_models.py:929\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    927\u001b[0m decoder \u001b[39m=\u001b[39m LineDecoder()\n\u001b[0;32m    928\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 929\u001b[0m     \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_text():\n\u001b[0;32m    930\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m decoder\u001b[39m.\u001b[39mdecode(text):\n\u001b[0;32m    931\u001b[0m             \u001b[39myield\u001b[39;00m line\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_models.py:916\u001b[0m, in \u001b[0;36mResponse.iter_text\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    914\u001b[0m chunker \u001b[39m=\u001b[39m TextChunker(chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[0;32m    915\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mfor\u001b[39;00m byte_content \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_bytes():\n\u001b[0;32m    917\u001b[0m         text_content \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(byte_content)\n\u001b[0;32m    918\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunker\u001b[39m.\u001b[39mdecode(text_content):\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    895\u001b[0m chunker \u001b[39m=\u001b[39m ByteChunker(chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[0;32m    896\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 897\u001b[0m     \u001b[39mfor\u001b[39;00m raw_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_raw():\n\u001b[0;32m    898\u001b[0m         decoded \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(raw_bytes)\n\u001b[0;32m    899\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunker\u001b[39m.\u001b[39mdecode(decoded):\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[1;34m(self, chunk_size)\u001b[0m\n\u001b[0;32m    948\u001b[0m chunker \u001b[39m=\u001b[39m ByteChunker(chunk_size\u001b[39m=\u001b[39mchunk_size)\n\u001b[0;32m    950\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request):\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mfor\u001b[39;00m raw_stream_bytes \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream:\n\u001b[0;32m    952\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_bytes_downloaded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(raw_stream_bytes)\n\u001b[0;32m    953\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunker\u001b[39m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream:\n\u001b[0;32m    154\u001b[0m         \u001b[39myield\u001b[39;00m chunk\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpx\\_transports\\default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[0;32m    126\u001b[0m     \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 127\u001b[0m         \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_httpcore_stream:\n\u001b[0;32m    128\u001b[0m             \u001b[39myield\u001b[39;00m part\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    406\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mIterator[\u001b[39mbytes\u001b[39m]:\n\u001b[0;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mfor\u001b[39;00m part \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream:\n\u001b[0;32m    404\u001b[0m             \u001b[39myield\u001b[39;00m part\n\u001b[0;32m    405\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39mwith\u001b[39;00m ShieldCancellation():\n\u001b[0;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[1;32m--> 342\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    333\u001b[0m     \u001b[39mwith\u001b[39;00m Trace(\u001b[39m\"\u001b[39m\u001b[39mreceive_response_body\u001b[39m\u001b[39m\"\u001b[39m, logger, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request, kwargs):\n\u001b[1;32m--> 334\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection\u001b[39m.\u001b[39m_receive_response_body(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    335\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    337\u001b[0m     \u001b[39m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[39m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     \u001b[39m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    200\u001b[0m timeout \u001b[39m=\u001b[39m timeouts\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    202\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    204\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mData):\n\u001b[0;32m    205\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mbytes\u001b[39m(event\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    218\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    219\u001b[0m     )\n\u001b[0;32m    221\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_h11_state\u001b[39m.\u001b[39mtheir_state \u001b[39m==\u001b[39m h11\u001b[39m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32me:\\itmtb-me\\langchain-agent\\venv\\lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    print(\"TOOL EXECUTED\")\n",
    "    return a * b\n",
    "\n",
    "def multiply_tool_wrapper(input_data):\n",
    "    try:\n",
    "        # Handle string like \"(12, 7)\"\n",
    "        if isinstance(input_data, str):\n",
    "            input_data = input_data.strip().replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\")\n",
    "            parts = input_data.split()\n",
    "            a, b = int(parts[0]), int(parts[1])\n",
    "        elif isinstance(input_data, (tuple, list)):\n",
    "            a, b = int(input_data[0]), int(input_data[1])\n",
    "        elif isinstance(input_data, dict):\n",
    "            a, b = int(input_data.get(\"a\")), int(input_data.get(\"b\"))\n",
    "        else:\n",
    "            return \"Error: Unsupported input format\"\n",
    "\n",
    "        result = a * b\n",
    "        print(\"TOOL EXECUTED\")\n",
    "        return f\"The result of {a} x {b} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "multiply_tool = Tool.from_function(\n",
    "    func=multiply_tool_wrapper,\n",
    "    name=\"multiply\",\n",
    "    description=\"Multiply two integers. Input should be like '(4, 5)' or '4 5'.\"\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[multiply_tool],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "prompt = \"Can u tell me a joke?\"\n",
    "response = agent.invoke({\"input\": prompt})\n",
    "print(\"Agent Response:\", response[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
